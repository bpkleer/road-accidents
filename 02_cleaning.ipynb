{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this step, I will take a look in each variable, to clean features before doing explorative analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries + load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for geo manipulation\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# loading data\n",
    "data = pd.read_csv(\n",
    "    'data/processed/merged.csv',\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target creation\n",
    "\n",
    "As I outlined in the `README.md`, the aim is to predict accident's overall severity score. Therefore, we need to built an index of severity based on individual gravity (`grav`). \n",
    "\n",
    "The formular to calculate the overall gravity is (see `README.md` for more information): \n",
    "\n",
    "$$Severity Score = \\frac{1}{n} \\sum_{i=1}^n is_i  + weight_{killed} * pk^{0.4} + weight_{hospital} * ph^{0.2}$$\n",
    "\n",
    "with $is$: individual score\n",
    "$pk$: persons killed\n",
    "$ph$: persons in hospital\n",
    "\n",
    "Hence, I need to create counts of `killed` and `hospital` per accident. \n",
    "\n",
    "For `gravity` values are: `-1` no information, `1` uninjured, `2` killed, `3` in hospital, `4` lightly injured. In the following, I first apply the values (in relation to AIS), sum the values over each accident and take the mean. Then I create two dummies `killed` and `hospital` that count the people killed and injured in hospital per accident. Finally, I apply the extra weights for the amount of person killed or in hospital per accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    1: 0,  # Uninjured, but involved\n",
    "    2: 6,  # killed\n",
    "    3: 3.5,  # injured in hospitel\n",
    "    4: 1,  # lightly injured\n",
    "    -1: 0.0,  # no information, nothing added\n",
    "}\n",
    "# based on scale for accident severity (see report)\n",
    "\n",
    "# applying weights to grav and save it in new feature\n",
    "data['grav_weighted'] = data['gravity'].map(weights)\n",
    "\n",
    "# summing up over accident\n",
    "data['severity_score'] = data.groupby('num_acc')[\n",
    "    'grav_weighted'].transform('mean')\n",
    "\n",
    "# Dummy: killed\n",
    "data['killed'] = [1 if gravity == 2 else 0 for gravity in data['gravity']]\n",
    "\n",
    "# Sum of killed per accident\n",
    "data['killed_n'] = data.groupby('num_acc')['killed'].transform('sum')\n",
    "\n",
    "# Dummy: Hospital\n",
    "data['hospital'] = [1 if gravity == 3 else 0 for gravity in data['gravity']]\n",
    "\n",
    "# Sum of in hospital per accident\n",
    "data['hospital_n'] = data.groupby('num_acc')['hospital'].transform('sum')\n",
    "\n",
    "# applying extra weight\n",
    "data['severity_score'] = (\n",
    "    data['severity_score']\n",
    "    + (data['killed_n'] * 6) ** 0.4\n",
    "    + (data['hospital_n'] * 3.5) ** 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I just have to drop the all features related to gravity except for `severity_score`. Furthermore, I can now just keep one line per accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_acc</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>light_condit</th>\n",
       "      <th>location_type</th>\n",
       "      <th>intersect_type</th>\n",
       "      <th>weather_cond</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>municip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>res_lane</th>\n",
       "      <th>prof_road</th>\n",
       "      <th>plan_view</th>\n",
       "      <th>tpc_length</th>\n",
       "      <th>width_road</th>\n",
       "      <th>surface</th>\n",
       "      <th>infra</th>\n",
       "      <th>acc_loc</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>severity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1900</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.034735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.034735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200500000003</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1845</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.034735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200500000004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1615</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.725773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200500000005</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1945</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.534735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_acc  month  day  time  light_condit  location_type  \\\n",
       "0   200500000001      1   12  1900             3              2   \n",
       "6   200500000002      1   21  1600             1              2   \n",
       "8   200500000003      1   21  1845             3              1   \n",
       "10  200500000004      1    4  1615             1              1   \n",
       "14  200500000005      1   10  1945             3              1   \n",
       "\n",
       "    intersect_type  weather_cond  collision_type municip_code  ... res_lane  \\\n",
       "0                1           1.0             3.0           11  ...      0.0   \n",
       "6                1           1.0             1.0           51  ...      1.0   \n",
       "8                1           2.0             1.0           51  ...      1.0   \n",
       "10               1           1.0             5.0           82  ...      0.0   \n",
       "14               1           3.0             6.0          478  ...      0.0   \n",
       "\n",
       "   prof_road plan_view tpc_length  width_road  surface  infra acc_loc  \\\n",
       "0        1.0       1.0        0.0        63.0      1.0    0.0     1.0   \n",
       "6        1.0       1.0        0.0       100.0      1.0    0.0     5.0   \n",
       "8        1.0       1.0        0.0         0.0      2.0    0.0     5.0   \n",
       "10       1.0       1.0        0.0         0.0      1.0    0.0     1.0   \n",
       "14       1.0       3.0        0.0        59.0      2.0    0.0     3.0   \n",
       "\n",
       "    max_speed severity_score  \n",
       "0         NaN       2.034735  \n",
       "6         NaN       3.034735  \n",
       "8         NaN       3.034735  \n",
       "10        NaN       3.725773  \n",
       "14        NaN       3.534735  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(\n",
    "    columns=[\n",
    "        'gravity', 'grav_weighted', 'killed', 'killed_n', 'hospital',\n",
    "        'hospital_n'\n",
    "    ],\n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "data.drop_duplicates(subset='num_acc', inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude and Longitude (main interest variables)\n",
    "\n",
    "I already perceived problems in the `lat` and `long` features: 1) showing a wrong decimal sign, 2) some missing values are coded with `-`. In the first case, I just need to replace the `,` with `.`, in the second case I need to set a `-` to missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['long'].unique()\n",
    "\n",
    "data['long'] = data['long'].astype(str)\n",
    "\n",
    "data['long'] = data['long'].str.replace(',', '.', regex=False)\n",
    "\n",
    "data.loc[data['long']=='-', 'long'] = np.nan\n",
    "\n",
    "data['long'] = data['long'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I do the same steps for latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lat'].unique()\n",
    "\n",
    "data['lat'] = data['lat'].astype(str)\n",
    "\n",
    "data['lat'] = data['lat'].str.replace(',', '.', regex=False)\n",
    "\n",
    "data.loc[data['lat']=='-', 'lat'] = np.nan\n",
    "\n",
    "data['lat'] = data['lat'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that it seems to be mixed of degrees and some other projected coordinate system (PCS) in the data, since some data falls in the range of lattitude (-90 to +90) and longitude (-180 to +180) in degrees, while some data is clearly out of bound (i.e., 50334). As you can see below, there are 736791 cases where this is the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326434\n"
     ]
    }
   ],
   "source": [
    "print(data['lat'][((data['lat'] > 90) | (data['lat'] < -90)) & ((data['long'] > 180) | (data['long'] < -180))].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there might be different approaches in typing in the lattitude and longitude data, I tried recoding with `geopandas` from different standards that might be used (EPSG:32631, EPSG:2154, ESPG:3395, and EPSG:27572), but none yielded in France. I inspected the transformations visually in `09-visualizations.ipynb` which showed incorrected data points. \n",
    "Hence, I filtered the data set to have only data within the limits of lattitude and longitude. This yielded to a correct amount of data within France. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create invalid df with only cases out of bound\n",
    "# invalid = data[\n",
    "#     (data['lat'] > 90) | (data['lat'] < -90) |\n",
    "#     (data['long'] > 180) | (data['long'] < -180)\n",
    "# ]\n",
    "\n",
    "# # create valid df with the rest of the data\n",
    "# valid = data[~data.index.isin(invalid.index)] \n",
    "\n",
    "# # assuming invalid rows in meters (EPSG:3395), create a GeoDataFrame\n",
    "# geom_invalid = [Point(xy) for xy in zip(invalid['long'], invalid['lat'])]\n",
    "# gdf_invalid = gpd.GeoDataFrame(invalid, geometry=geom_invalid)\n",
    "\n",
    "# # setting CRS for the invalid data (assuming they are in EPSG:2154)\n",
    "# gdf_invalid.set_crs(epsg=32631, inplace=True)\n",
    "\n",
    "# # reprojecting to WGS84 (EPSG:4326)\n",
    "# gdf_invalid = gdf_invalid.to_crs(epsg=4326)\n",
    "\n",
    "# # extracting latitude and longitude from GeoDataFrame\n",
    "# gdf_invalid['lat'] = gdf_invalid.geometry.y\n",
    "# gdf_invalid['long'] = gdf_invalid.geometry.x\n",
    "\n",
    "# # combining valid data with reprojected data\n",
    "# data = pd.concat([valid, gdf_invalid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\n",
    "    (data['lat'] < -90) | (data['lat'] > 90) | \n",
    "    (data['long'] < -180) | (data['long'] > 180), \n",
    "    ['lat', 'long']\n",
    "] = np.nan\n",
    "\n",
    "data.dropna(subset=['long', 'lat'], inplace=True)\n",
    "\n",
    "data = data[data['lat'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I lastly check if any data point is still outside of France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data['lat'][((data['lat'] < 41.3037) | (data['lat'] > 51.1242)) & ((data['long'] < -5.3163) | (data['long'] > 9.6625))].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we get 0 above, on the map in `09-visualizations.ipynb`, I saw one point in the gulf of Guinea which is clearly not mainland France. This might be a data point, that is plotted by degrees, however the input might be different, and therefore create wrong points which would mess with the algorithms. Since the original format is not given and the trials above did not lead to a sufficient solution, there is only deleting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19678\n"
     ]
    }
   ],
   "source": [
    "print(data['lat'][((data['lat'] >= 3.5) & (data['lat'] <= 5.5)) & ((data['long'] >= -0.1) & (data['long'] <= 0.1))].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\n",
    "    ~(((data['lat'] >= 3.5) & (data['lat'] <= 5.5)) & \n",
    "    ((data['long'] >= -0.1) & (data['long'] <= 0.1)))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for the remaining features, if any feature has high missing values. Features with missings over 40% will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_acc            0.000000\n",
       "month              0.000000\n",
       "day                0.000000\n",
       "time               0.000000\n",
       "light_condit       0.000000\n",
       "location_type      0.000000\n",
       "intersect_type     0.000000\n",
       "weather_cond       0.000000\n",
       "collision_type     0.000000\n",
       "municip_code       0.000000\n",
       "adr                2.214121\n",
       "gps_code          81.101064\n",
       "lat                0.000000\n",
       "long               0.000000\n",
       "dep                0.000000\n",
       "year               0.000000\n",
       "road_cat           0.000000\n",
       "road_num          10.075593\n",
       "road_num_index     2.824859\n",
       "v2                90.467285\n",
       "traffic_dir        0.000000\n",
       "num_lanes          0.000000\n",
       "pr                 0.000000\n",
       "pr1                0.000000\n",
       "res_lane           0.000000\n",
       "prof_road          0.000000\n",
       "plan_view          0.000000\n",
       "tpc_length        99.884007\n",
       "width_road        14.031184\n",
       "surface            0.000000\n",
       "infra              0.000000\n",
       "acc_loc            0.000000\n",
       "max_speed          0.000000\n",
       "severity_score     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's the case for:\n",
    "\n",
    "- `road_num_index`\n",
    "- `v2`\n",
    "- `max_speed`\n",
    "\n",
    "All other features will be inspected, probably more features will be deleted, since no information is sometimes coded as `0` or `-1` which is equal to NA but not detected above. Features with low NA's will be handled in feature engineering after test-train split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `light_condit`\n",
    "\n",
    "I turned `-1` no information to `NA` (3 cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light_condit\n",
      " 1    83854\n",
      " 5    19824\n",
      " 3    13204\n",
      " 2     8591\n",
      " 4     1256\n",
      "-1        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['light_condit'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['light_condit'] == -1, 'light_condit'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `location_type`\n",
    "\n",
    "All good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_type\n",
      "2    80202\n",
      "1    46530\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['location_type'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `intersect_type`\n",
    "\n",
    "Values with `-1`/`0` no information turned to `NA` (17 cases). A lot of categories, further check in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersect_type\n",
      " 1    80677\n",
      " 2    16030\n",
      " 3    14238\n",
      " 6     5481\n",
      " 9     5184\n",
      " 4     2789\n",
      " 7     1289\n",
      " 5      770\n",
      " 8      263\n",
      "-1       11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['intersect_type'].value_counts(dropna=False))\n",
    "\n",
    "# no information to NA\n",
    "data.loc[data['intersect_type'] == -1, 'intersect_type'] = np.nan\n",
    "data.loc[data['intersect_type'] == 0, 'intersect_type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersect_type\n",
      "1.0    80677\n",
      "2.0    16030\n",
      "3.0    14238\n",
      "6.0     5481\n",
      "9.0     5184\n",
      "4.0     2789\n",
      "7.0     1289\n",
      "5.0      770\n",
      "8.0      263\n",
      "NaN       11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['intersect_type'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `weather_cond`\n",
    "\n",
    "Values with `-1` turned to `NA` (3 cases). A lot of categories, further check in feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather_cond\n",
      " 1.0    100097\n",
      " 2.0     13799\n",
      " 8.0      5059\n",
      " 3.0      2930\n",
      " 7.0      2447\n",
      " 5.0       951\n",
      " 9.0       638\n",
      " 4.0       437\n",
      " 6.0       368\n",
      "-1.0         6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['weather_cond'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['weather_cond'] == -1, 'weather_cond'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather_cond\n",
      "1.0    100097\n",
      "2.0     13799\n",
      "8.0      5059\n",
      "3.0      2930\n",
      "7.0      2447\n",
      "5.0       951\n",
      "9.0       638\n",
      "4.0       437\n",
      "6.0       368\n",
      "NaN         6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['weather_cond'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `collision_type`\n",
    "\n",
    "Cases with no information (`-1`) turned to `NA` (65 cases). A lot of categories, further check in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collision_type\n",
      " 6.0    38365\n",
      " 3.0    37837\n",
      " 2.0    16794\n",
      " 1.0    13084\n",
      " 7.0    12397\n",
      " 4.0     4529\n",
      " 5.0     3660\n",
      "-1.0       66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['collision_type'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['collision_type'] == -1, 'collision_type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collision_type\n",
      "6.0    38365\n",
      "3.0    37837\n",
      "2.0    16794\n",
      "1.0    13084\n",
      "7.0    12397\n",
      "4.0     4529\n",
      "5.0     3660\n",
      "NaN       66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['collision_type'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `municip_code`\n",
    "\n",
    "Code for the municipial region based on INSEE. Regard that this correlates with the `dep` variable which has the department code based on INSEE. I explore this further in the feature engineering. There is one case with `N/C` value which is turned to `NA`.\n",
    "\n",
    "Usually, the INSEE code for municipialities has 5 numbers, and the first two indicate the department and the last 3 the municipalities. However, as you can see below, majority of the entries here is lower than $10000$, indicating an odd format for INSEE for municipalities. Hence, I drop this variable and might only include `dep` next to the lattitude and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "municip_code\n",
      "75116    1287\n",
      "75112     949\n",
      "75119     907\n",
      "75117     899\n",
      "75115     884\n",
      "         ... \n",
      "49201       1\n",
      "64131       1\n",
      "88375       1\n",
      "30019       1\n",
      "17083       1\n",
      "Name: count, Length: 17399, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['municip_code'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['municip_code']=='N/C', 'municip_code'] = np.nan\n",
    "\n",
    "data['municip_code'] = data['municip_code'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "municip_code\n",
       "False    120025\n",
       "True       6706\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insee_test = data['municip_code'] < 10000\n",
    "\n",
    "insee_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `adr`\n",
    "\n",
    "This information is also captured by longitude and lattitude with more precision. It captures street names (categorical) and has 447383 unique values. I drop this variable, since the information with longitude and lattitude can be better used in the algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58099"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['adr'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gps_code`\n",
    "\n",
    "This variable has only one level, since I only deal with mainland France. I drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gps_code\n",
      "NaN    102781\n",
      "M       23951\n",
      "Name: count, dtype: int64\n",
      "['M' nan]\n"
     ]
    }
   ],
   "source": [
    "print(data['gps_code'].value_counts(dropna=False))\n",
    "\n",
    "print(data['gps_code'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dep`\n",
    "\n",
    "Inconsistent data. Regarding [government pages](https://www.insee.fr/fr/information/7766585), code for department only have 2 digits, except for oversea territories which have digits over 970. The variable also has geographical information since each department can be represented in an array of longitude and longitude, therefore, I drop the feature here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dep\n",
      "75    12062\n",
      "93     6720\n",
      "92     6082\n",
      "13     5562\n",
      "94     5539\n",
      "      ...  \n",
      "70      256\n",
      "8       253\n",
      "48      189\n",
      "90      113\n",
      "23      104\n",
      "Name: count, Length: 94, dtype: int64\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]\n"
     ]
    }
   ],
   "source": [
    "print(data['dep'].value_counts(dropna=False))\n",
    "\n",
    "print(data['dep'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `month`\n",
    "\n",
    "Stays at it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month\n",
      "6     12038\n",
      "2     11669\n",
      "1     11649\n",
      "10    11496\n",
      "9     11419\n",
      "5     10975\n",
      "7     10728\n",
      "11    10209\n",
      "3      9587\n",
      "8      9448\n",
      "12     9053\n",
      "4      8461\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['month'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `day`\n",
    "\n",
    "stays as it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day\n",
      "7     4476\n",
      "14    4458\n",
      "20    4436\n",
      "16    4385\n",
      "18    4354\n",
      "21    4343\n",
      "19    4326\n",
      "13    4316\n",
      "8     4315\n",
      "11    4290\n",
      "9     4285\n",
      "12    4260\n",
      "22    4255\n",
      "4     4252\n",
      "17    4245\n",
      "10    4242\n",
      "24    4232\n",
      "15    4223\n",
      "6     4157\n",
      "23    4143\n",
      "25    4111\n",
      "5     4082\n",
      "26    4019\n",
      "3     3973\n",
      "27    3918\n",
      "28    3857\n",
      "2     3843\n",
      "1     3841\n",
      "29    3555\n",
      "30    3438\n",
      "31    2102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['day'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable does not give a lot of information, because a day is very different among months and years. What could be interesting, to have a variable showing which day of the week it was assuming on weekdays accidents might be more frequent/severe.\n",
    "Therefore, I recode `day` into `weekday`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data[['year', 'month', 'day']])\n",
    "\n",
    "data['weekday'] = data['date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday\n",
       "4    20929\n",
       "2    18621\n",
       "1    18360\n",
       "3    18312\n",
       "5    18056\n",
       "0    17071\n",
       "6    15383\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['weekday'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `time`\n",
    "\n",
    "Some values have still `:`. For consistency, and hour extraction, I delete the `:`. Furthermore, some values only have two digits, sometimes above 24. Probably, these values indicate 0:43. None of these values if above 59, hence, it seems senseful to recode these with a leading 0 for midnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "18:00    1617\n",
      "17:00    1482\n",
      "18:30    1426\n",
      "17:30    1348\n",
      "19:00    1318\n",
      "         ... \n",
      "02:31       1\n",
      "03:01       1\n",
      "04:01       1\n",
      "05:39       1\n",
      "03:59       1\n",
      "Name: count, Length: 1437, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['time'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete `:` in time\n",
    "def del_colon(value):\n",
    "    if ':' in (str(value)):\n",
    "        new = str(value).replace(':', '')\n",
    "        return new\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "data['time'] = data['time'].apply(del_colon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "1800    1617\n",
      "1700    1482\n",
      "1830    1426\n",
      "1730    1348\n",
      "1900    1318\n",
      "        ... \n",
      "0231       1\n",
      "0301       1\n",
      "0401       1\n",
      "0539       1\n",
      "0359       1\n",
      "Name: count, Length: 1437, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['time'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hours(value):\n",
    "    if len(str(value)) <= 4 and len(str(value)) >= 3:\n",
    "        if str(value).startswith('0'):\n",
    "            return int(str(value)[1:-2])\n",
    "        else:\n",
    "            return int(value) // 100\n",
    "    elif len(str(value)) <= 2 and len(str(value)) >= 1:\n",
    "        return 0\n",
    "    elif len(str(value)) > 4:\n",
    "        print(value)\n",
    "    else:\n",
    "        print(value)\n",
    "    \n",
    "data['hour'] = data['time'].apply(get_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour\n",
      "17    10910\n",
      "18    10575\n",
      "16     9291\n",
      "19     8082\n",
      "15     7663\n",
      "8      7576\n",
      "14     6778\n",
      "12     6596\n",
      "9      6297\n",
      "13     6267\n",
      "11     6179\n",
      "10     5737\n",
      "7      5699\n",
      "20     5611\n",
      "21     3879\n",
      "22     3322\n",
      "23     2782\n",
      "6      2715\n",
      "0      2335\n",
      "1      2009\n",
      "5      1864\n",
      "2      1714\n",
      "4      1435\n",
      "3      1416\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['hour'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: time, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "data['time'] = data['time'].astype(float)\n",
    "\n",
    "print(data['time'][(data['time'] < 100) & (data['time'] > 59)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `year`\n",
    "\n",
    "Stays as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2022    51772\n",
      "2023    51009\n",
      "2019    17901\n",
      "2021     6050\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['year'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `road_cat`\n",
    "\n",
    "Has a lot of categories, will be checked in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road_cat\n",
      "4.0    53839\n",
      "3.0    48821\n",
      "1.0    12578\n",
      "2.0     5585\n",
      "7.0     4203\n",
      "6.0      961\n",
      "9.0      607\n",
      "5.0      138\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['road_cat'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `road_num`\n",
    "\n",
    "In regard to longitude and lattitude it has no new information, therefore I drop it. Usually road numbers have a prefix like A for highways and N for long distance national roads, D for department roads, C for municipal roads and E for European roads. With just the number, it is not clearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road_num\n",
      "NaN                        12769\n",
      "7                            958\n",
      "86                           938\n",
      "4                            789\n",
      "6                            746\n",
      "                           ...  \n",
      "PAGESE (DOMAINE DE LA)         1\n",
      "Boulevard Pierre 1er           1\n",
      "PAUL VALERY                    1\n",
      "FOCH. PLACE DU MARECHAL        1\n",
      "KAMPMANN (RUE)                 1\n",
      "Name: count, Length: 27475, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['road_num'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `traffic_dir`\n",
    "\n",
    "Keep it so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_dir\n",
      " 2.0    77513\n",
      " 1.0    22747\n",
      " 3.0    17882\n",
      "-1.0     7862\n",
      " 4.0      728\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['traffic_dir'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['traffic_dir'] == -1, 'traffic_dir'] = np.nan\n",
    "data.loc[data['traffic_dir'] == 0, 'traffic_dir'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_dir\n",
      "2.0    77513\n",
      "1.0    22747\n",
      "3.0    17882\n",
      "NaN     7862\n",
      "4.0      728\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06203642331849888"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['traffic_dir'].value_counts(dropna=False))\n",
    "\n",
    "data['traffic_dir'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `num_lanes`\n",
    "\n",
    "It should indicate the number of road lanes where the accident happened. However, it has quite odd numbers over 12 (Champs Elysee has 10), however, these are few cases. Furthermore, there are some strings, which were recoded to `NA`, too. With the other `NA's` these might be recoded in the feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_lanes\n",
      "2               66535\n",
      "4               11991\n",
      "1               11271\n",
      "2.0             10811\n",
      "3                8658\n",
      "0                2686\n",
      "6                2598\n",
      " -1              2241\n",
      "4.0              2200\n",
      "1.0              1713\n",
      "5                1572\n",
      "3.0              1239\n",
      "8                 715\n",
      "6.0               564\n",
      "0.0               443\n",
      "5.0               326\n",
      "-1.0              230\n",
      "7                 205\n",
      "8.0               189\n",
      "10                125\n",
      "7.0                83\n",
      "-1                 67\n",
      "9                  65\n",
      "#VALEURMULTI       52\n",
      "10.0               49\n",
      "9.0                34\n",
      "12                 31\n",
      "11                 18\n",
      "12.0               11\n",
      "11.0                9\n",
      "#ERREUR             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['num_lanes'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_lanes\n",
      "2.0     77346\n",
      "4.0     14191\n",
      "1.0     12984\n",
      "3.0      9897\n",
      "NaN      5720\n",
      "6.0      3162\n",
      "5.0      1898\n",
      "8.0       904\n",
      "7.0       288\n",
      "10.0      174\n",
      "9.0        99\n",
      "12.0       42\n",
      "11.0       27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def set_int(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "data['num_lanes'] = data['num_lanes'].apply(set_int)\n",
    "\n",
    "data.loc[data['num_lanes'] == -1, 'num_lanes'] = np.nan\n",
    "data.loc[data['num_lanes'] == 0, 'num_lanes'] = np.nan\n",
    "data.loc[data['num_lanes'] == ' -1', 'num_lanes'] = np.nan\n",
    "\n",
    "print(data['num_lanes'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045134614777641004"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_lanes'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pr`\n",
    "\n",
    "After a first easy correction from no information to NA, crossed threshold of more than 30% NA's. Therefore, I dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr\n",
      "0        29286\n",
      "(1)      22244\n",
      " -1      18157\n",
      "1         6214\n",
      "2         2734\n",
      "         ...  \n",
      "513          1\n",
      "520          1\n",
      "346          1\n",
      "1111         1\n",
      "4Â 400        1\n",
      "Name: count, Length: 539, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3743569106460878"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['pr'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['pr'] == ' -1', 'pr'] = np.nan\n",
    "data.loc[data['pr'] == '0', 'pr'] = np.nan\n",
    "\n",
    "data['pr'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pr1`\n",
    "\n",
    "Dropped as above, since there are more than 50% without information or NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr1\n",
      "0        31220\n",
      "(1)      22506\n",
      " -1      18291\n",
      "1         4156\n",
      "500       4110\n",
      "         ...  \n",
      "1616         1\n",
      "1538         1\n",
      "1152         1\n",
      "1188         1\n",
      "3Â 139        1\n",
      "Name: count, Length: 1585, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39067480983492725"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['pr1'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['pr1'] == ' -1', 'pr1'] = np.nan\n",
    "data.loc[data['pr1'] == '0', 'pr1'] = np.nan\n",
    "\n",
    "data['pr1'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `res_lane`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has a lot of `NA's` (including no information `0`/`-1`). Nearly 93% have NA or no information, therefore I dropped the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_lane\n",
      " 0.0    110011\n",
      " 1.0      6597\n",
      " 3.0      4595\n",
      " 2.0      3898\n",
      "-1.0      1631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['res_lane'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['res_lane'] == 0, 'res_lane'] = np.nan\n",
    "data.loc[data['res_lane'] == -1, 'res_lane'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_lane\n",
      "NaN    111642\n",
      "1.0      6597\n",
      "3.0      4595\n",
      "2.0      3898\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8809298361897547"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['res_lane'].value_counts(dropna=False))\n",
    "\n",
    "data['res_lane'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `prof_road`\n",
    "\n",
    "Has a lot of `NA's`. Will be further inspected in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_road\n",
      " 1.0    103205\n",
      " 2.0     19803\n",
      " 3.0      1957\n",
      " 4.0      1724\n",
      "-1.0        43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['prof_road'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['prof_road'] == 0, 'prof_road'] = np.nan\n",
    "data.loc[data['prof_road'] == -1, 'prof_road'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_road\n",
      "1.0    103205\n",
      "2.0     19803\n",
      "3.0      1957\n",
      "4.0      1724\n",
      "NaN        43\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00033929867752422436"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['prof_road'].value_counts(dropna=False))\n",
    "\n",
    "data['prof_road'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `plan_view`\n",
    "\n",
    "Has a lot of `NA's`. Will be further inspected in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan_view\n",
      " 1.0    102344\n",
      " 2.0     11948\n",
      " 3.0     10763\n",
      " 4.0      1640\n",
      "-1.0        37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['plan_view'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['plan_view'] == 0, 'plan_view'] = np.nan\n",
    "data.loc[data['plan_view'] == -1, 'plan_view'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan_view\n",
      "1.0    102344\n",
      "2.0     11948\n",
      "3.0     10763\n",
      "4.0      1640\n",
      "NaN        37\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0002919546760092163"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['plan_view'].value_counts(dropna=False))\n",
    "\n",
    "data['plan_view'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tpc_length`\n",
    "\n",
    "Has a lot of `NA's`/no information. Also super high values over 200m. Due to high missing/no information (~91%) dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc_length\n",
      "NaN      126585\n",
      "0.0          56\n",
      "0            17\n",
      "3            11\n",
      "2             7\n",
      "5             5\n",
      "2.5           5\n",
      "3,5           3\n",
      "2,5           3\n",
      "6             3\n",
      "4             2\n",
      "6,5           2\n",
      "7             2\n",
      "2.0           2\n",
      "5.5           1\n",
      "18.0          1\n",
      "6,21          1\n",
      "6,2           1\n",
      "13,45         1\n",
      "8             1\n",
      "1             1\n",
      "50.0          1\n",
      "6,31          1\n",
      "10,5          1\n",
      "3,2           1\n",
      "0,4           1\n",
      "5,5           1\n",
      "1,5           1\n",
      "35.0          1\n",
      "40            1\n",
      "1.0           1\n",
      "10            1\n",
      "5,25          1\n",
      "2,8           1\n",
      "3,1           1\n",
      "20.0          1\n",
      "1.5           1\n",
      "30.0          1\n",
      "6,8           1\n",
      "13            1\n",
      "0,8           1\n",
      "12,5          1\n",
      "4,5           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['tpc_length'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['tpc_length'] == '0.0', 'tpc_length'] = np.nan\n",
    "data.loc[data['tpc_length'] == -1, 'tpc_length'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc_length\n",
      "NaN      126641\n",
      "0            17\n",
      "3            11\n",
      "2             7\n",
      "2.5           5\n",
      "5             5\n",
      "3,5           3\n",
      "2,5           3\n",
      "6             3\n",
      "2.0           2\n",
      "6,5           2\n",
      "7             2\n",
      "4             2\n",
      "5,5           1\n",
      "1,5           1\n",
      "6,21          1\n",
      "0,4           1\n",
      "3,2           1\n",
      "6,2           1\n",
      "10            1\n",
      "6,31          1\n",
      "1             1\n",
      "8             1\n",
      "13,45         1\n",
      "10,5          1\n",
      "3,1           1\n",
      "5,25          1\n",
      "2,8           1\n",
      "50.0          1\n",
      "6,8           1\n",
      "13            1\n",
      "0,8           1\n",
      "12,5          1\n",
      "40            1\n",
      "5.5           1\n",
      "30.0          1\n",
      "1.5           1\n",
      "20.0          1\n",
      "1.0           1\n",
      "35.0          1\n",
      "18.0          1\n",
      "4,5           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9992819493103557"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['tpc_length'].value_counts(dropna=False))\n",
    "\n",
    "data['tpc_length'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `width_road`\n",
    "\n",
    "Some inconsistent values (wrong decimal, too broad roads). The broadest road in France is Avenue Foch with 120 meters. However, lot of NA's and no information values (`0`/`-1`), therefore dropped. Also information is also captured in `num_lanes`, since the number of lanes is directly connected to `width_road`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width_road\n",
      " -1      89450\n",
      "NaN      17782\n",
      "7         3980\n",
      "4         3273\n",
      "5,5       3051\n",
      "         ...  \n",
      "730.0        1\n",
      "6.05         1\n",
      "170.0        1\n",
      "34.0         1\n",
      "2,85         1\n",
      "Name: count, Length: 191, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['width_road'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['width_road'] == '0.0', 'width_road'] = np.nan\n",
    "data.loc[data['width_road'] == -1, 'width_road'] = np.nan\n",
    "data.loc[data['width_road'] == \" -1\", 'width_road'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width_road\n",
      "NaN     107232\n",
      "7         3980\n",
      "4         3273\n",
      "5,5       3051\n",
      "5         2071\n",
      "         ...  \n",
      "90.0         1\n",
      "7,45         1\n",
      "49.0         1\n",
      "3.8          1\n",
      "2,85         1\n",
      "Name: count, Length: 190, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8461319950762238"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['width_road'].value_counts(dropna=False))\n",
    "\n",
    "data['width_road'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `surface`\n",
    "\n",
    "`NA's` will be handled in feature engineering in addition to meaningful groups in this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface\n",
      " 1.0    101410\n",
      " 2.0     23273\n",
      " 9.0       641\n",
      " 7.0       542\n",
      " 5.0       235\n",
      " 3.0       214\n",
      " 8.0       209\n",
      " 6.0        99\n",
      "-1.0        58\n",
      " 4.0        51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['surface'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['surface'] == 0, 'surface'] = np.nan\n",
    "data.loc[data['surface'] == -1, 'surface'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface\n",
      "1.0    101410\n",
      "2.0     23273\n",
      "9.0       641\n",
      "7.0       542\n",
      "5.0       235\n",
      "3.0       214\n",
      "8.0       209\n",
      "6.0        99\n",
      "NaN        58\n",
      "4.0        51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['surface'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `infra`\n",
    "\n",
    "Ca. 92% is NA or no information. Dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infra\n",
      " 0.0    106298\n",
      " 5.0      6795\n",
      " 9.0      4289\n",
      " 2.0      2234\n",
      " 3.0      1553\n",
      " 1.0      1534\n",
      "-1.0      1333\n",
      " 6.0      1269\n",
      " 8.0       948\n",
      " 4.0       390\n",
      " 7.0        89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['infra'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['infra'] == 0, 'infra'] = np.nan\n",
    "data.loc[data['infra'] == -1, 'infra'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infra\n",
      "NaN    107631\n",
      "5.0      6795\n",
      "9.0      4289\n",
      "2.0      2234\n",
      "3.0      1553\n",
      "1.0      1534\n",
      "6.0      1269\n",
      "8.0       948\n",
      "4.0       390\n",
      "7.0        89\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8492803711769719"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['infra'].value_counts(dropna=False))\n",
    "\n",
    "data['infra'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `acc_loc`\n",
    "\n",
    "`NA's` will be handled in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_loc\n",
      " 1.0    104697\n",
      " 3.0      9332\n",
      " 8.0      4284\n",
      " 5.0      3026\n",
      " 4.0      2796\n",
      " 6.0      1512\n",
      " 2.0       991\n",
      "-1.0        94\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['acc_loc'].value_counts(dropna=False))\n",
    "\n",
    "data.loc[data['acc_loc'] == 0, 'acc_loc'] = np.nan\n",
    "data.loc[data['acc_loc'] == -1, 'acc_loc'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_loc\n",
      "1.0    104697\n",
      "3.0      9332\n",
      "8.0      4284\n",
      "5.0      3026\n",
      "4.0      2796\n",
      "6.0      1512\n",
      "2.0       991\n",
      "NaN        94\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0007417226904017928"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['acc_loc'].value_counts(dropna=False))\n",
    "\n",
    "data['acc_loc'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping variables + cases\n",
    "\n",
    "First, I drop cases, where I don't have information on longitude or lattitude (`NA` or `0`). Next I drop the variables I decided above: `municip_code`, `gps_code`, and `adr`. The cases `0` occured in lattitude and this is not meaningful, since lattitude 0 is the equator. In addition, I delete the identifier `num_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\n",
    "    columns=[\n",
    "        'municip_code', 'adr', 'gps_code', 'dep', 'road_num', \n",
    "        'road_num_index', 'v2', 'max_speed', 'pr', 'pr1',\n",
    "        'res_lane', 'tpc_length', 'width_road', 'infra', \n",
    "        'time', 'day', 'num_acc',         \n",
    "    ], \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/processed/clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
